{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuitive Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Assume, the underlying true function $f$ that dictates the relationship between $x$ and $y$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ f(x) = \\frac{1}{2} x + \\sqrt{max(x, 0)}-cosx+2 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return .5 * x + np.sqrt(np.max(x, 0)) - np.cos(x) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the noise is modeled by a Gaussian with zero mean and standard deviation 1, $œµ \\approx ùí©(0, 1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_epsilon = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, $y = f(x) + œµ$. Let's randomly generate 1,000 points from this process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "#generating x values for this example\n",
    "x_max = 3\n",
    "x = 3 * (2 * np.random.rand(N) - 1)\n",
    "\n",
    "#generating epsilon values for this example\n",
    "epsilon = sigma_epsilon * np.random.randn(N)\n",
    "\n",
    "#generating y values for this example\n",
    "y = f(x) + epsilon\n",
    "\n",
    "#generating y_test values for this example\n",
    "y_test = f(3.2) + sigma_epsilon * np.random.randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we get the following plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the graph\n",
    "plt.figure(figsize=(12, 6))\n",
    "x_range = np.linspace(-x_max, x_max, 1000)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x_range, f(x_range), 'r', linewidth=3.0)\n",
    "plt.scatter(x_test, y_test, c='r')\n",
    "plt.xlabel('x', size=12)\n",
    "plt.ylabel('y', size=12)\n",
    "plt.xticks(np.arange(-x_max, x_max + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blue dots represent $(x, y)$ pairs and red line is the underlying true function $f(x)$. Red dot is the unseen (test) point we want to predict. We see that f follows a non-linear pattern due to the addition of square root and cosine in the function‚Äôs definition. For our purposes, these 1,000 points represent the whole underlying population. Here is the code to reproduce this plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now model the problem with polynomial regressions of varying degrees of complexity. As a reminder, in polynomial regression we try to fit the following non-linear relationship between $x$ and $y$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{f}(x) = w_0 + w_1x+w_2x^2+ . \\ . \\ . + w_dx^d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, we try to approximate $y$ with $\\hat{f}(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_hat(x, w):\n",
    "    d = len(w) - 1\n",
    "    return np.sum(w * np.power(x, np.expand_dims(np.arange(d, -1, -1), 1)).T, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, let‚Äôs assume we could only use 20 points (out of the 1,000) to train our polynomial regression model and we consider four different regression models, one with degree d=1 (simple line), one with d=2, d=3 and d=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining training points to be 20\n",
    "n = int(.02 * N)\n",
    "\n",
    "#defining other stuff\n",
    "x_test = 3.2\n",
    "x_range = np.linspace(-x_max, x_max, 1000)\n",
    "colors = np.array(['tab:green', 'tab:purple', 'tab:cyan', 'tab:orange'])\n",
    "\n",
    "#defining degrees\n",
    "d_arr = [1, 2, 3, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we randomly sample 20 points from the underlying population and we repeat this experiment 6 times, this is a possible outcome we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the graphs\n",
    "cnt = 1\n",
    "fig, axs = plt.subplots(2, 3, sharey=True, figsize=(15, 9))\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        idx = np.random.permutation(N)[:n]\n",
    "        x_train, y_train = x[idx], y[idx]\n",
    "        \n",
    "        w = []\n",
    "        for d in d_arr:\n",
    "            w.append(np.polyfit(x_train, y_train, d))\n",
    "                \n",
    "        axs[i, j].scatter(x_train, y_train)\n",
    "        axs[i, j].plot(x_range, f(x_range), 'r', linewidth=3.0)\n",
    "        for k in range(len(w)):\n",
    "            axs[i, j].plot(x_range, f_hat(x_range, w[k]), colors[k], linewidth=3.0)\n",
    "            \n",
    "        axs[i, j].scatter(x_test, y_test, c='r')\n",
    "        for k in range(len(w)):\n",
    "            axs[i, j].scatter(x_test, f_hat(x_test, w[k]), c=colors[k])\n",
    "                \n",
    "        axs[i, j].set_xlabel('x', size=12)\n",
    "        axs[i, j].set_ylabel('y', size=12)\n",
    "        axs[i, j].legend([r'$f$', r'$\\hat{f}$ (d = 1)', r'$\\hat{f}$ (d = 2)', \n",
    "                          r'$\\hat{f}$ (d = 3)', r'$\\hat{f}$ (d = 5)'], fontsize=12)\n",
    "        axs[i, j].title.set_text('experiment {}'.format(cnt))\n",
    "        cnt += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blue dots represent the 20 training data points for a specific realization (experiment). The red line is the underlying (unknown to us) true function $f$ and the other lines represent the fitting of the four different models to different realizations of training data. The green, purple, cyan, orange dots represent the prediction $\\hat{f}(x)$ of test (unseen) point x under each model. As we see, there‚Äôs less variation in lines with smaller degrees of complexity. Take for instance $d=1$ (simple line). The slope of the line does not change all that much between different experiments. On other other hand, a more complex model ($d=5$) is much more sensitive to small fluctuations in the training data. See for example the difference in the orange line ($d=5$) between experiment 1 and 6 and how this affects prediction $\\hat{f}(x)$. This is the variance problem we mentioned in previous sections. A simplistic model is very robust to changes in training data, but a more complex is not. On other hand, the deviation of $\\hat{f}(x)$ from $f(x)$ on average (the bias), is larger for more simplistic models, since our assumptions are not as representative of the underlying true relationship $f$. Here is the code for the above plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-Variance Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some data for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9037e4e81669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.02\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "R = 10000\n",
    "n = int(.02 * N)\n",
    "n_test = 1000\n",
    "x_max = 3\n",
    "d_arr = np.arange(5)\n",
    "\n",
    "#generating x_test and epsilon values for this example\n",
    "x_test = x_max + np.random.rand(n_test) - .5\n",
    "epsilon = sigma_epsilon * np.random.randn(n_test)\n",
    "\n",
    "#generating y_test values for this example\n",
    "y_test = f(x_test) + epsilon\n",
    "\n",
    "#generating train_squared_error values for this example\n",
    "train_squared_error = np.zeros((len(d_arr), R))\n",
    "\n",
    "#generating y_hat_test values for this example\n",
    "y_hat_test = np.zeros((len(d_arr), R, n_test))\n",
    "for r in range(R):\n",
    "    n = int(.02 * N)\n",
    "    idx = np.random.permutation(N)[:n]\n",
    "    x_train, y_train = x[idx], y[idx]\n",
    "    for k in range(len(d_arr)):\n",
    "        d = d_arr[k]\n",
    "        w = np.polyfit(x_train, y_train, d)\n",
    "        train_squared_error[k, r] = np.mean((y_train - f_hat(x_train, w)) ** 2)\n",
    "        y_hat_test[k, r, :] = f_hat(x_test, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let‚Äôs consider 1,000 test points and compute the average test MSE (over these points). We also compute the average squared bias (over these 1,000 test points) and average variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ MSE = E \\ [(y-\\hat{f}(x))^2] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining MSE error       \n",
    "test_squared_error = np.mean((y_hat_test - y_test) ** 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Bias = ( \\ E[\\hat{f}(x)] - f(x) \\ )^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining bias\n",
    "bias_squared = (np.mean(y_hat_test, 1) - f(x_test)) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Variance = E \\ [(\\hat{f}(x)-E[\\hat{f}(x)])^2] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variance\n",
    "var_y_hat_test = np.var(y_hat_test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do this for five models, from degree d=0 (horizontal line) all the way to degree d=4, we get the following plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(d_arr, np.mean(test_squared_error, 1), 'g', linewidth=3.0)\n",
    "plt.plot(d_arr, np.mean(train_squared_error, 1), 'k', linewidth=3.0)\n",
    "plt.plot(d_arr, np.mean(bias_squared, 1), 'y--')\n",
    "plt.plot(d_arr, np.mean(var_y_hat_test, 1), 'b--')\n",
    "plt.plot(d_arr, (sigma_epsilon ** 2) * np.ones_like(d_arr), 'r--')\n",
    "\n",
    "plt.xticks(d_arr)\n",
    "plt.xlabel('d', size=12)\n",
    "plt.legend(['test error', 'training error', r'bias squared: $(\\mathbb{E}[\\hat{f}(x)] - f(x))^2$',\n",
    "            r'$var(\\hat{f}(x))$', r'irreducible error: $\\sigma_\\epsilon^2$'], loc='upper center', fontsize=12)\n",
    "\n",
    "plt.ylim([0, 12])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
